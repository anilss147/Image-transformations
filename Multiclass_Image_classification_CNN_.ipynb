{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Multiclass Image classification CNN .ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/anilss147/Image-transformations/blob/main/Multiclass_Image_classification_CNN_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eR7f-JFjTe7i",
        "outputId": "45a1bbb7-f05b-4e49-883d-b9fdb1ab6d57"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hijvstgxADfq",
        "outputId": "c0bf7a64-1ddd-470e-a66d-548d678ec733"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L19tWOA9os5i"
      },
      "source": [
        "import cv2\n",
        "import os\n",
        "import glob\n",
        "import pandas as pd\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n7ZEPlQ-AGq2"
      },
      "source": [
        "\n",
        "base_dir2 = '/content/drive/MyDrive/SACK_THURSDAY2'\n",
        "\n",
        "train_dir2 = os.path.join(base_dir2, 'train')\n",
        "\n",
        "validation_dir2 =os.path.join(base_dir2, 'validation')\n",
        "\n",
        "train_arielblue_dir = os.path.join(train_dir2, 'ARIELRED')\n",
        "\n",
        "train_ATIDEPLUS_dir = os.path.join(train_dir2, 'ATIDEPLUS')\n",
        "\n",
        "train_BARIELBLUE_dir = os.path.join(train_dir2, 'BARIELBLUE')\n",
        "\n",
        "train_CONVEYOR_dir = os.path.join(train_dir2, 'CONVEYOR')\n",
        "\n",
        "train_TIDEYELLOW_dir = os.path.join(train_dir2, 'TIDEYELLOW')\n",
        "\n",
        "train_UNKNOWN_dir = os.path.join(train_dir2, 'UNKNOWN')\n",
        "\n",
        "train_ARIELBLUE_2000_dir = os.path.join(train_dir2, 'ARIELBLUE_2000')\n",
        "\n",
        "train_TIDEPLUS_2000_dir = os.path.join(train_dir2, 'TIDEPLUS_2000')\n",
        "\n",
        "train_TIDEYELLOW_2000_test_dilr = os.path.join(train_dir2, 'TIDEYELLOW_2000_test')\n",
        "\n",
        "train_ARIELRED_2000_test_dilr = os.path.join(train_dir2, 'ARIELRED_2000')\n",
        "\n",
        "validation_arielblue_dir = os.path.join(validation_dir2, 'ARIELRED')\n",
        "\n",
        "validation_ATIDEPLUS_dir = os.path.join(validation_dir2, 'ATIDEPLUS')\n",
        "\n",
        "validation_BARIELBLUE_dir = os.path.join(validation_dir2, 'BARIELBLUE')\n",
        "\n",
        "validation_CONVEYOR_dir = os.path.join(validation_dir2, 'CONVEYOR')\n",
        "\n",
        "validation_TIDEYELLOW_dir = os.path.join(validation_dir2, 'TIDEYELLOW')\n",
        "\n",
        "validation_UNKNOWN_dir = os.path.join(validation_dir2, 'UNKNOWN')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rn1diryWneib"
      },
      "source": [
        "train_all = [train_arielblue_dir,train_ATIDEPLUS_dir,train_BARIELBLUE_dir,train_CONVEYOR_dir,train_ARIELRED_2000_test_dilr,train_TIDEYELLOW_dir,train_TIDEYELLOW_2000_test_dilr,train_UNKNOWN_dir,train_ARIELBLUE_2000_dir,train_TIDEPLUS_2000_dir]\n",
        "validation_all = [validation_arielblue_dir,validation_ATIDEPLUS_dir,validation_BARIELBLUE_dir,validation_CONVEYOR_dir,validation_TIDEYELLOW_dir,validation_UNKNOWN_dir]\n",
        "imag_name_list = []\n",
        "for input_dir in train_all + validation_all:\n",
        "  im_names = sorted(glob.glob(os.path.join(input_dir, '*.jpeg')))\n",
        "  for i,im_name in enumerate(im_names):\n",
        "    imag_name_list.append(im_name)\n",
        "data = pd.DataFrame({\"image_path\":imag_name_list})\n",
        "lbl = ['ARIELBLUE','TIDEYELLOW','ARIELRED','UNKNOWN','TIDEPLUS','CONVEYOR']#,'TIDEPLUS'\n",
        "def label_fn(path):\n",
        " for i,l in enumerate(lbl):\n",
        "    if l in path:\n",
        "      return i\n",
        "data[\"label\"] = data.image_path.apply(lambda x: label_fn(x))\n",
        "data.to_csv(\"train.csv\",index=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3iQDIo4s2uUn"
      },
      "source": [
        "data.label.value_counts()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HZ7HbFxKAWNc"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import Model\n",
        "import numpy as np\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBuBxU7aGrT4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d7da8a5-5efb-430a-aa03-c6a102ccdc89"
      },
      "source": [
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from sklearn.model_selection import train_test_split\n",
        "# All images will be rescaled by 1./255\n",
        "# All images will be rescaled by 1./255\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range = 40, \n",
        "                                   shear_range = 0.2, \n",
        "                                   zoom_range = 0.2, \n",
        "                                   horizontal_flip = True, \n",
        "                                   brightness_range = (0.5, 1.5))\n",
        "val_datagen = ImageDataGenerator(rescale=1./255,\n",
        "                                   rotation_range = 40, \n",
        "                                   shear_range = 0.2, \n",
        "                                   zoom_range = 0.2, \n",
        "                                   horizontal_flip = True, \n",
        "                                   brightness_range = (0.5, 1.5))\n",
        "\n",
        "\n",
        "train = pd.read_csv(\"/content/train.csv\")\n",
        "xtrain,xtest,ytrain,ytest = train_test_split(train.image_path,train.label,test_size=0.1,shuffle = True )\n",
        "train_df = pd.DataFrame({\"img\":xtrain.values,\"label\":ytrain.values.astype(np.str)})\n",
        "val_df = pd.DataFrame({\"img\":xtest.values,\"label\":ytest.values.astype(np.str)})\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "train_generator = train_datagen.flow_from_dataframe(\n",
        "    dataframe=train_df,\n",
        "        directory=\"\",\n",
        "        x_col=\"img\",\n",
        "        y_col = \"label\",  # This is the source directory for training images\n",
        "        target_size=(150, 150),  # All images will be resized to 150x150\n",
        "        batch_size=20,\n",
        "        # Since we use binary_crossentropy loss, we need binary labels\n",
        "        class_mode='categorical')\n",
        " \n",
        "# Flow validation images in batches of 20 using val_datagen generator\n",
        "validation_generator = val_datagen.flow_from_dataframe(\n",
        "        dataframe=val_df,\n",
        "        x_col = \"img\",\n",
        "        y_col = \"label\",\n",
        "        directory=\"\",\n",
        "        target_size=(150, 150),\n",
        "        batch_size=2,\n",
        "        class_mode='categorical')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 24970 validated image filenames belonging to 6 classes.\n",
            "Found 2775 validated image filenames belonging to 6 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8IjFH24t2MPq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f16baed2-416c-43c6-9762-184d5be7f124"
      },
      "source": [
        "train_generator.class_indices"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tBskKxvFcaKC",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "81123958-955a-4e99-8066-5b50510619e4"
      },
      "source": [
        "import tensorflow as tf\n",
        "tf.test.gpu_device_name()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/device:GPU:0'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "idN9VXpbQbqk"
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "#import keras                                                            \n",
        "with tf.device(\"/device:GPU:0\"):\n",
        "  cnn = tf.keras.models.Sequential()\n",
        "  cnn.add(tf.keras.layers.Conv2D(filters=48, kernel_size=3, activation='relu', input_shape=[150, 150, 3]))\n",
        "  cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "  cnn.add(tf.keras.layers.Conv2D(filters=48, kernel_size=3, activation='relu'))\n",
        "  cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "  cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "  cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))\n",
        "  cnn.add(tf.keras.layers.Flatten())\n",
        "  cnn.add(tf.keras.layers.Dense(128, activation='relu'))\n",
        "  cnn.add(tf.keras.layers.Dense(64, activation='relu'))\n",
        "  cnn.add(tf.keras.layers.Dense(6, activation='softmax'))\n",
        "  cnn.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n",
        "  cnn.fit(x=train_generator, validation_data=validation_generator, epochs=20)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fnil4Y5oYWmQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7cdbfe58-b371-4087-a903-2c7f3c04ced1"
      },
      "source": [
        "cnn.history"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f10802039b0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1i9doiIVYYhv"
      },
      "source": [
        "cnn.get_config()\n",
        "#cnn.history"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YMPXlbuYap2"
      },
      "source": [
        "np.mean(cnn.history['acc'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0eMgwauPzsVz"
      },
      "source": [
        "cnn.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mX9wc5T_u4ID"
      },
      "source": [
        "t = \"513\"\n",
        "export_path_keras1 = '/content/drive/MyDrive/NEWNETWORK/model/3 12'#+\"/{}.h5\".format(int(t))\n",
        "export_path_keras = '/content/drive/MyDrive/NEWNETWORK/model/3 12'+\"/{}.h5\".format(int(t))\n",
        "print(export_path_keras)\n",
        "cnn.save(export_path_keras1)\n",
        "cnn.save(export_path_keras)\n",
        "\n",
        "class_map = train_generator.class_indices\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x7PKyAhHP4b9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "50b77454-8d82-4627-9165-83b5565c1716"
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8B9FzH8RvaKv"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "\n",
        "path = '/content/drive/MyDrive/NEWNETWORK/model/3 12/513.h5'\n",
        "reloaded = tf.keras.models.load_model(\n",
        "  path, \n",
        "  # `custom_objects` tells keras how to load a `hub.KerasLayer`\n",
        "  custom_objects={'KerasLayer': hub.KerasLayer})\n",
        "\n",
        "reloaded.summary()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jK7SAJqqw_hI"
      },
      "source": [
        "import numpy as np\n",
        "from keras_preprocessing import image\n",
        "\n",
        "test_image = image.load_img(\"/content/drive/MyDrive/SACK_THURSDAY2/train/CONVEYOR/1(100).jpeg\",target_size = (150,150))\n",
        "\n",
        "test_image1 = image.img_to_array(test_image)\n",
        "test_image2 = np.expand_dims(test_image1, axis =0)\n",
        "result = reloaded.predict(test_image2)\n",
        "\n",
        "print((result))\n",
        "print((result[0][0]))\n",
        "print((result[0][1]))\n",
        "print((result[0][2]))\n",
        "print((result[0][3]))\n",
        "print((result[0][4]))\n",
        "print((result[0][5]))\n",
        "#lbl = ['ARIELBLUE','TIDEYELLOW','ARIELRED','UNKNOWN','TIDEPLUS','CONVEYOR']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cYdPWakhviIt"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iAaENvSq0HG"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}